import os
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split

# ğŸ“Œ Ù…Ø³Ø§Ø± Ù…Ù„Ù CSV
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(BASE_DIR, '..', 'processed_dataset.csv')

# ğŸ“¥ Ù‚Ø±Ø§Ø¡Ø© CSV
df = pd.read_csv(csv_path)

# ğŸ§¹ Ø­Ø°Ù Ø§Ù„ØµÙˆØ± Ø§Ù„ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©
df['full_path'] = df['image_path'].apply(lambda x: os.path.abspath(os.path.join(BASE_DIR, x)))
df = df[df['full_path'].apply(os.path.exists)]

print(f"ğŸ§¹ {len(df)} images valides trouvÃ©es.")

# âœ‚ï¸ ØªÙ‚Ø³ÙŠÙ… Train / Val
train_df = df[df['type'] == 'train']
val_df = df[df['type'] == 'test']

print(f"ğŸ§ª Train samples: {len(train_df)}")
print(f"ğŸ§ª Validation samples: {len(val_df)}")

# ğŸš« Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª
if len(train_df) == 0 or len(val_df) == 0:
    raise ValueError("ğŸš« Dataset vide aprÃ¨s filtrage. VÃ©rifiez les chemins et les types dans le CSV.")

# ğŸ“¦ Dataset loader
def load_image(image_path):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [224, 224])
    image = tf.cast(image, tf.float32) / 255.0
    return image

def get_dataset(dataframe):
    paths = dataframe['full_path'].values
    labels = dataframe['emotion'].values
    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))
    dataset = dataset.map(lambda x, y: (load_image(x), y))
    return dataset.batch(32).shuffle(100)

# ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_ds = get_dataset(train_df)
val_ds = get_dataset(val_df)

# ğŸ§  Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø³ÙŠØ·
model = models.Sequential([
    layers.Input(shape=(224, 224, 3)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(df['emotion'].nunique(), activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# ğŸ‹ï¸ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
model.fit(train_ds, validation_data=val_ds, epochs=10)
